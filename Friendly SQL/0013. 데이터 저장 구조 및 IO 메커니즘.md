# 데이터 저장 구조 및 I/O 메커니즘


## SQL이 느린 이유 
SQL이 느린 이유는 십중팔구 I/O때문이다. 구체적으로 말해, 디스크 I/O 때문이다. 그렇다면, I/O란 무엇인가?  OS 또는 I/O 서브시스템이 I/O를 처리하는 동안 프로세스는 쉰다. 프로세스가 일하지 않고 쉬는 이유는 여러가지가 있지만 I/O가 가장 대표적이고 절대 비중을 차지한다. 

프로세스는 실행중인 프로그램이며, 생성 이후 종료 전까지 준비, 실행, 대기 상태를 반복한다. 실행 중인 프로세스는 인터럽트에 의해 수시로 실행 준비 상태로 전환했다가 다시 실행 상태로 전환한다. 여러 프로세스가 하나의 CPU를 공유할 수 있지만, 특정 순간에는 하나의 프로세스만 CPU를 사용할 수 있기 때문에 이런 매커니즘이 필요하다. 

인터럽트 없이 열심히 일하던 프로세스도 디스크에서 데이터를 읽어야 할 땐 CPU를 OS에 반환하고 잠시 대기상태에서 I/O가 완료되기를 기다린다. 정해진 OS함수를 호출(I/O Call)하고 CPU를 반환한 채 알람을 설정하고 대기 큐(Wait Queue)에서 잠을 자는 것이다. 열심히 일해야 할 프로세스가 한가하게 쉬고 있으니 I/O가 많으면 성능이 느릴 수 밖에 없다. 

I/O Call 속도는 Single Block I/O 기준으로 평균 10ms쯤 된다. 초당 100 블록쯤 읽는 셈이다. 큰 캐시를 가진 SAN 스토리지는 4~8ms쯤 된다. 초당 125~250 블록쯤 읽는 셈이다. SSD까지 활용하는 최근 스토리지는 1~2ms, 즉 초당 500~1000 블록쯤 읽는다.  
스토리지 성능이 빨라지고 있지만, 여전히 우리 기대에는 못 미친다. 어떤 SQL이 Single Block I/O 방식으로 10000 블록을 읽는다면, 가장 최신 스토리지에서도 10초이상 기다려야한다. 전반적으로 I/O튜닝이 안된 시스템이라면 수많은 프로세스에 의해 동시다발적으로 발생하는 I/O Call 때문에 디스크 경합이 심해지고 그만큼 대기 시간도 늘어난다. 10초가 아니라 20초를 기다려야할 수도 있다는 뜻이다. SQL이 느린 이유가 바로 여기에 있다. 디스크 I/O 때문이다. 디스크 I/O가 SQL 성능을 좌우한다고 해도 과언이 아니다. 
I/O 매커니즘을 자세히 설명하기에 앞서 데이터베이스 저장 구조부터 살펴보자. 


## 데이터베이스 저장 구조
데이터를 저장하려면 먼저 테이블스페이스를 생성해야한다. 테이블스페이스는 세그먼트를 담는 콘테이너로서, 여러 개의 데이터파일(디스크 상의 물리적인 OS파일)로 구성된다. 

테이블스페이스를 생성하면 세그먼트를 생성한다. 세그먼트는 테이블, 인덱스처럼 데이터 저장공간이 필요한 오브젝트다. 테이블, 인덱스를 생성할 때 어떤 테이블스페이스에 저장할지를 지정한다.  정의된 크기만큼 테이블스페이스가 생성되면 데이터가 그 크기를 넘을 때 까지 지정된 크기를 유지한다. 만약 정의된 크기보다 큰 데이터 입력이 생길 경우 자동으로 크기가 확장된다. 

세그먼트는 여러 익스텐트로 구성된다. 파티션 구조가 아니라면 테이블도 하나의 세그먼트이고, 인덱스도 하나의 세그먼트다. 테이블 또는 인덱스가 파티션 구조라면, 각 파이션이 하나의 세그먼트가 된다. LOB컬럼은 그 자체가 하나의 세그먼트를 구성하므로 자신이 속한 테이블과 다른 별도 공간에 값을 저장한다. 

익스텐트는 공간을 확장하는 단위다. 테이블이나 인덱스에 데이터를 입력하다가 공간이 부족해지면 해당 오브젝트가 속한 테이블스페이스로부터 익스텐트를 추가로 할당받는다. 익스텐트는 연속된 블록들의 집합이기도 하다. 익스텐트는 여러 개의 데이터 블록으로 구성된다. 

익스텐트 단위로 공간을 확장하지만, 사용자가 입력한 레코드를 실제로 저장하는 공간은 데이터 블록이다. 블록 대신 페이지라는 용어를 사용하는 DBMS도 있다. 한 블록은 하나의 테이블이 독점 관리한다. 즉, 한 블록에 저장된 레코드는 모두 같은 테이블 레코드다. 

한 익스텐트도 하나의 테이블이 독점한다. 즉, 한 익스텐트에 담긴 블록은 모두 같은 테이블 블록이다.  MS-SQL Server는 한 익스텐트를 여러 오브젝트가 같이 사용할 수도 있다. 

세그먼트는 공간이 부족해지면 테이블스페이스로부터 익스텐트를 추가로 할당받는다고 했는데, 세그먼트에 할당된 모든 익스텐트가 같은 데이터파일에 위치하지 않을 수 있다. 사실 서로 다른 데이터파일에 위치할 가능성이 높다. 하나의 테이블스페이스를 여러 데이터파일로 구성하면, 파일 경합을 줄이기 위해 DBMS가 데이터를 가능한 여러 데이터 파일로 분산해서 저장하기 때문이다. 익스텐트 내 블록은 서로 인접한 연속된 공간이지만, 익스텐트끼리는 연속된 공간이 아니다. 

블록, 익스텐트, 세그먼트, 테이블스페이스, 데이터파일을 간단히 정의하면 다음과 같다. 

* 블록: 데이터를 읽고 쓰는 단위
* 익스텐트: 공간을 확장하는 단위, 연속된 블록 집합
* 세그먼트: 데이터 저장공간이 필요한 오브젝트(테이블, 인덱스, 파티션, LOB 등)
* 테이블스페이스: 세그먼트를 담는 컨테이너
* 데이터파일: 디스크 상의 물리적인 OS파일


## 블록단위 I/O
DBMS가 데이터를 읽고 쓰는 단위는 블록이다. 데이터 I/O 단위가 블록이므로 특정 레코드 하나를 읽고 싶어도 해당 블록을 통째로 읽는다. 심지어 1Byte짜리 컬럼 하나만 읽고 싶어도 블록을 통째로 읽는다. 테이블뿐만 아니라 인덱스도 블록 단위로 데이터를 읽고 쓴다. 

## 시퀀셜 액세스 vs 랜덤 액세스
테이블 또는 인덱스 블록을 엑세스하는 방식으로는 시퀀셜 액세스와 랜덤 액세스 두가지가 있다. 

##### 시퀀셜 액세스
시퀀셜 액세스는 논리적 또는 물리적으로 연결된 순서에 따라 차례대로 블록을 읽는 방식이다. 인덱스 리프 블록은 앞뒤를 가리키는 주소값을 통해 논리적으로 서로 연결되어 있다. 이 주소 값에 따라 앞 또는 뒤로 순차적으로 스켄하는 방식이 시퀀셜 엑세스다.  하지만 테이블 블록 간에는 서로 논리적인 연결고리를 갖고 있지 않다. 오라클은 세그먼트를 해당된 익스텐트 목록을 세그먼트 헤더에 맵으로 관리한다. 익스텐트 맵은 각 익스텐트의 첫 번째 블록 주소 값을 갖는다. 읽어야할 익스텐트 목록을 익스텐트 맵에서 얻고, 각 익스텐의 첫 번째 블록 뒤에 연속해서 저장된 블록을 순서대로 읽으면, 그것이 곧 Full Table Scan 이다. 

##### 랜덤 액세스
랜덤 엑세스는 논리저그 물리적 순서를 따르지 않고, 레코드 하나를 읽기 위해 한 블록씩 접근하는 방식이다. 


## 논리적 I/O vs 물리적 I/O

### DB버퍼캐시
디스크 I/O가 성능을 결정한다. SQL을 수행하는 과정에서 계속해서 데이터 블록을 읽는데, 자주 읽는 블록을 매번 디스크에서 읽는 것은 매우 비효율적이다. 모든 DBMS에 데이터 캐싱 매커니즘이 필수인 이유다. 데이터를 캐싱하는 DB버퍼캐시도 SGA(System Global Area)의 가장 중요한 구성요소 중 하나다. 라이브러리 캐시가 SQL과 실행계획, DB저장형 함수/ 프로시저 등을 캐싱하는 "코드 캐시"라고 한다면, DB버퍼캐시는 "데이터 캐시"라고 할 수 있다. 디스크에서 어렵게 읽은 데이터 블록을 캐싱해 둠으로써 같은 블록에 대한 반복적인 I/O를 줄이는데 목적이 있다. 

서버 프로세스와 데이터파일 사이에 버퍼캐시가 있으므로 데이터블록을 읽을 땐 한상 버퍼캐시부터 탐색한다. 운 좋게 캐시에서 블록을 찾는다면 바쁜 시간에 프로세스가 I/O Call을 하고 쉬지 않아도 된다. 운이 없어서 캐시에서 못 찾아도, 한번은 I/O Call을 하겠지만, 같은 블록을 다시 읽을 때는 쉬지 않아도 된다. 버퍼 캐시는 공유 메모리 영역이므로 같은 블록을 읽는 다른 프로세스도 득을 본다. 


### 논리적 I/O vs 물리적 I/O
논리적 I/O는 SQL을 처리하는 과정에서 발생한 총 블록 I/O를 말한다. 일반적으로 메모리상의 버퍼 캐시를 경유하므로 메모리 I/O가 곧 논리적 I/O라고 생각해도 무방하다. 메모리를 경유하지 않는 Direct Path I/O를 고려하면, 논리적 I/O는 메모리 I/O와 Direct Path I/O를 더한 개념이다. 
 물리적 블록 I/O는 디스크에서 발생한 총 블록 I/O를 말한다. SQL 처리 도중 읽어야 할 블록을 버퍼캐시에서 찾지 못할 때만 디스크를 액세스하므로 논리적 블록 I/O 중 일부를 물리적으로 I/O한다. 
메모리 I/O는 전기적 신호인데 반해 디스크 I/O는 엑세스 암을 통해 물리적 작용이 일어나므로 메모리 I/O에 비해 상당히 느리다. 보통 10000배쯤 느리다. 디스크 경합이 심할 때는 더 느리다. 

### 왜 논리적 I/O인가
SQL을 수행하려면 데이터가 담긴 블록을 읽어야 한다. SQL이 참조하는 테이블에 데이터를 입력하거나 삭제하지 않는 상황에서 조건절에 같은 변수 값을 입력하면, 아무리 여러 번 실행해도 매번 읽는 블록 수는 같다. SQL을 수행하면서 읽은 총 블록 I/O가 논리적 I/O다  
Direct Path Read 방식으로 읽는 경우를 제외하면 모든 블록은 DB 버퍼 캐시를 경유해서 읽는다. 따라서 논리적 I/O 횟수는 일반적으로 DB버퍼캐시에서 블록을 읽은 횟수와 일치한다. 논리적 I/O가 메모리 I/O와 같은 개념은 아니지만 결과적으로 수치는 같다.  
DB버퍼캐시에서 블록을 찾지 못해 디스크에서 읽은 블록 I/O가 물리적 I/O다. 데이터 입력이나 삭제가 없어도 물리적 I/O는 SQL을 실행할 때마다 다르다. 첫번쨰 실행할 때보다 두버째 실행할 때 줄어들고, 세번째 실행할 때 더 줄어든다. 연속해서 실행하면 DB버퍼캐시에서 해당 테이블 블록의 점유율이 높이지기 때문이다. 한참 후에 다시 실행하면 반대로 물리적 I/O가 늘어난다. DB 버퍼가 다른 테이블 블록으로 채워지기 때문이다. 


### 버퍼캐시히트율

$BCHR=　(캐시에서 곧바로 찾은 블록 수 / 총 읽은 블록 수) × 100$  

$　　　=　((논리적 I/O - 물리적 I/O) / 논리적 I/O) × 100$  

$　　　=　(1 -(물리적 I/O / 논리적 I/O)) × 100$  

$　　　=　(1 -(Dist / (Query + Current))) × 100$  

공식에서 알 수 있듯 BCHR은 읽은 전체 블록 중에서 물리적 디스크 I/O를 수반하지 않고 곧바로 메모리에서 찾은 비율을 나타낸다. 애플리케이션 특성에 따라 다르지만, 온라인 트랜잭션을 주로 처리하는 애플리케이션이라면 시스템 레벨에서 평균 99% 히트율을 달성해야한다. 핵심 트랜잭션이 시스템 전체 부하의 대부분을 차지하므로 열심히 튜닝하면 99%는 결코 달성하기 어려운 수치가 아니다. 

BCHR 공식에서 우리는 중요한 성능 원리를 발견할 수 있다. 물리적 I/O가 성능을 결정하지만, 실제 SQL 성능을 향상하려문 물리적 I/O가 아닌 논리적 I/O를 줄여야한다는 사실이다.  BCHR 공식을 아래와 같이 변형하면 쉽게 알 수 있다. 

$물리적 I/O = 논리적 I/O × (100\% - BCHR)$ 

논리적 I/O는 일정하므로 물리적 I/O는 BCHR에 의해 결정된다. BCHR은 시스템 상황에 따라 달라지므로 물리적 I/O는 결국 시스템 상황에 의해 결정되는 통제 불가능한 외생변수다. SQL 성능을 높이기 위해서 할 수 있는 일은 논리적 I/O를 줄이는 일뿐이다. 예를 들어 시스템 레벨 BCHR이 평균 70%라고 할 때, 특정 SQL의 논리적 I/O가 10000개면 물리적 I/O는 대략 3000개쯤 발생할 것으로 예상할 수 있다. 

논리적 I/O를 1000개로 줄이면 물리적 I/O도 300으로 감소하고, 성능도 10배 향상된다. 

그렇다면 논리적 I/O는 어떻게 줄일 수 있을까? SQL을 튜닝해서 읽는 총 블록 개수를 줄이면 된다. 논리적 I/O는 항상 일정하게 발생하지만 SQL 튜닝을 통해 줄일 수 있는 통제 가능한 내생변수다. __논리적 I/O를 줄임으로써 물리적 I/O를 줄이는 것이 곧 SQL 튜닝__ 이다. 

요약하면 BCHR 공식을 이루는 물리적 I/O는 통제 불가능한 외생변수다. 메모리를 증설해서  DB버퍼 캐시 크기를 늘리는 방법 외에 이것을 직접 줄일 방법은 없다. 반면, 논리적 I/O는 통제 가능한 내생변수다. SQL을 통해서 논리적 I/O를 줄이면 물리적 I/O도 줄고, 그만큼 성능도 향샹된다.

BCHR에는 주의해야할 함정이 있다. BCHR이 SQL 성능을 좌유하지만, BCHR이 높다고 해서 효율적인 SQL을 의미하지는 않는다는 사실이다. 같은 블록을 비효율적으로 반복해서 읽으면 BCHR이 높아진다. 


## Sinble Block I/O vs Multiblock I/O
메모리 캐시가 클수록 좋지만, 데이터를 모두 캐시에 적재할 수는 없다. 비용적인 한계, 기술적인 한계 때문에 전체 데이터 중 일부만 캐시에 적재해서 읽을 수 있다. 캐시에서 찾지 못한 데이터 블록은 I/O Call을 통해 디스크에서 DB버퍼캐시로 적재하고서 읽는다. I/O Call 할 때, 한 번에 한 블록씩 요청하기도 하고, 여러 블록씩 요청하기도 한다. 
한 번에 한 블록씩 요청해서 메모리에 적재하는 방식을 Single Block I/O라고 한다. 많은 벽돌을 실어 나를 때 손수레를 이용하는 것처럼 한 번에 여러 블록씩 요청해서 메모리에 적재하는 방식을 Multiblock I/O라고 한다. 

인덱스를 이용할 때는 기본적으로 인덱스와 테이블 블록 모두 Single Block I/O 방식을 사용한다. 구체적으로 아래 목록이 Single Block I/O 대상 오퍼레이션이며, 인덱스는 소량의 데이터를 읽을 때 주로 사용하므로 이 방식이 효율적이다. 

* 인덱스 루트 블록을 읽을 때
* 인덱스 루트 블록에서 얻은 주소 정보로 브랜치 블록을 읽을 때
* 인덱스 브랜치 블록에서 얻은 주소 정보로 리프 블록을 읽을 때
* 인덱스 리프 블록에서 얻은 주소 정보로 테이블 블록을 읽을 때

반대로, 많은 데이터 블록을 읽을 때는 Multiblock I/O 방식이 효율적이다. 그래서 인덱스를 이용하지 않고 테이블 전체를 스캔할 때 이 방식을 사용한다. 테이블이 클수록 Multiblock I/O 단위도 크면 좋다. 그 이유는 그만큼 프로세스 대기 상태를 줄여주기 때문이다. 

읽고자하는 블록을 DB 버퍼캐시에서 찾지 못한다면 해당 블록을 디스크에서 읽기 위해 I/O Call을 한다. 그동안 프로세스는 대기 큐에서 기다린다. 대용량 테이블이면 수많은 블록을 디스크에서 읽는 동안 여러차례 대기상태에 빠진다. 기왕 대기한다면 한번에 많은 요청을 해야 대기하는 횟수를 줄이고 성능을 높일 수 있다. 대용량 테이블을 Full Scan 할 때 Multiblock I/O 단위를 크게 설정하면 성능이 좋아지는 이유다. 

정리하면 MultiBlock I/O는 캐시에서 찾지 못한 특정 블록을 읽으려고 I/O Call할 때 디스크 상에 그 블록과 인접한 블록을 한꺼번에 읽어 캐시에 미리 적재하는 기능이다. 
DBMS 블록 사이즈가 얼마건 간에 OS 단에서 보통 1MB 단위로 I/O를 수행한다. 한번 I/O할때마다 1MB씩 읽는데, 한번에 읽을 수 있는 만큼 최대한 많이 읽는 것이 유리하다. 

일반적으로 OS 레벨 I/O 단위가 1MB, 오라클 레벨 I/O 단위가 8KB이므로 이 파라미터를 128로 설정하면 담을 수 있는 만큼 최대한 담게 된다. 어차피 그 이상 읽을 수 없으므로 그 이상으로 설정해도 소용없다. 오라클 레벨에서 그렇게 설정할 순 있지만 OS는 자신의 I/O 단위만큼씩만 읽는다. 

인접블록이란 같은 익스텐트에 속한 블록을 의미한다. Multiblock I/O 방식으로 읽더라도 익스텐트 경계를 넘기 못한다는 뜻이다. 예를 들어서 한 익스텐트에 20개의 블록이 담겨 있고, Multiblock I/O 단위가 8이라고 할 때, 세 번째 I/O Call에서는 4개 불록만 얻게 된다. 남은 4개를 더 읽을 수 있지만 더 읽기 위해 다음 익스텐트까지 읽지는 않는다. 


## Table Full Scan vs Index Range Scan
테이블에 저장된 데이터를 읽는 방식은 두 가지다. 테이블 전체를 스캔해서 읽는 방식과 인덱스를 이용해서 읽는 방식이다.  
Table Full Scan은 말 그대로 테이블에 속한 블록 전체를 읽어서 사용자가 원하는 데이터르 찾는 방식이다. 인덱스를 이요한 데이블 액세스는 인덱스에서 일정량을 스캔하면서 얻는 ROWID로 테이블 레코드를 찾아가는 방식이다. ROWID는 테이블 레코드가 디스크 상에 어디에 저장됐는지를 가리키는 위치 정보다. 

Table Full Scan 찾아내기식 실행계획 분석은 실제로 SQL 성능을 향상하는 데 큰 도움이 되지 않는다. 인덱스를 사용해야하는 상황인데 Table Full Scan을 하는 경우도 있으므로 전혀 의미가 없다고는 할 수 없지만, Table Full Scan은 피해야 한다는 많은 개발자의 인식과 달리 인덱스가 SQL의 성능을 떨어뜨리는 경우도 상당히 많기 때문이다. 
한 번에 많은 데이터를 처리하는 집계용 SQL과 배치프로그램이 특히 그렇다. 그ㅐ서 이들 프로그램에서 사용하는 SQL은 온라인 SQL(온라인 트랜잭션 처리 시스템에서 사용하는 SQL)보다 튜닝하기 비교적 쉽다. 다 그런건 아니지만, 상당수가 Table Full Scan으로 유도하면 성능이 빨라진다. 조인을 포함한 SQL이면 조인 메소드로 해시 조인을 선택해주면 된다. 

인덱스를 이용하는데 왜 성능이 더 나빠질까? Table Full Scan은 시퀀셜 액세스와 Multiblock I/O 방식으로 디스크 블록을 읽는다. 한 블록에 속한 모든 레코드를 한 번에 읽어 들이고, 캐시에서 못 찾으면 한번의 대기상태(I/O Call)을 통해 인전합 수십~ 수백 개 블록을 한꺼번에 I/O하는 매커니즘이다. 이 방식을 사용하는 SQL은 스토리지 스캔성능이 좋아지는 만큼 성능도 좋아진다. 

시퀀셜 액세스와 Multiblock I/O가 아무리 좋아도 수십~ 수백 건의 소량 데이터를 찾을 때 수백만~ 수천만 건의 데이터를 스캔하는 것은 비효율적이다. 큰 테이블에서 소량 데이터를 검색할 때는 반드시 인덱스를 이용해야 한다. 

Index Range Scan을 통한 테이블 엑세스는 랜덤 액세스와 Single Block I/O 방식으로 디스크 블록을 읽는다. 캐시에서 블록을 못 찾으면 레코드 하나를 읽기 위해 매번 대기상태에 빠지는 I/O 매커니즘이다. 따라서 많은 데이터르 읽을 때는 Table Full Scan보다 불리하다. 열심히 일해야할 프로세스가 대기상태에 빠지는데 스토리지 성능이 좋아지면 뭐하겠는가. 이 방식을 사용하는 SQL은 스토리지 스캔 성능이 수십 배 좋아졋도 성능이 조금 밖에 좋아지지 않는다. 

게다가 이 방식은 읽었던 블록을 반복해서 읽는 비효율이 있다. 많은 데이터를 읽을 때 물리적인 I/O뿐만 아니라 논리적인 블록 I/O 측면에서도 불리하다는 얘기다. 한 블록에 평균 500개의 레코드가 있으면 같은 블록을 최대 500번 읽는다. 만약 인덱스를 이용해 전체 레코드를 액세스한다면, 모든 블록을 평균 500회씩 읽게 되는 셈이다. 각 블록을 단 한 번에 읽는 Table Full Scan보다 훨씬 불리하다. 

데이터베이스를 효과적으로 이용하는 데 있어 인덱스의 중요성은 아무리 강조해도 지나치치 않지만, 인덱스에 대한 맹신은 금물이다. 인덱스가 항상 옳은 것은 아니며, 바꿔 말해 Table Full Scan이 항상 나쁜 것도 아니다. 인덱스는 큰 테이블에서 아주 적은 일부 데이터를 빨리 찾기 위한 도구일 뿐이므로 모은 성능 문제를 인덱스로 해결하려 해선 안된다. 읽을 데이터가 일정량을 넘으면 인덱스보다 Table Full Scan이 유리하다. 


## 캐시 탐색 메커니즘
Direct Path I/O를 제외한 모든 블록 I/O는 메모리 버퍼 캐시를 경유한다. 구체적으로 아래 오퍼레이션은 모두 버퍼캐시 탐색 과정을 거친다.
* 인덱스 루트 블록을 읽을 때 
* 인덱스 루트 블록에서 얻은 주소 정보로 브랜치 블록을 읽을 때
* 인덱스 브랜치 블록에서 얻은 주소 정보로 리프 블록을 읽을 때
* 인덱스 리프 블록에서 얻은 주소 정보로 테이블 블록을 읽을 때
* 테이블 블록을 Full Scan할 때

인덱스 루트 블록 주소는 SQL을 파싱하고 최적화하는 시점에 SQL 커서에 담긴다. 
Table Full Scan할 때는 읽어야할 블록 목록을 익스텐트 맵에서 얻는다. 

버퍼캐시 탐색 매커니즘을 설명하기에 앞서 버퍼캐시 구조부터 살펴보자. DBMS는 버퍼캐시를 해시구조로 관리한다. 버퍼캐시에서 블록을 찾을 때는 해시 알고리즘으로 버퍼 헤더를 찾고 거기서 얻은 포인터로 버퍼 블록을 액세스하는 방식을 사용한다. 해시 구조의 특징을 요약하면 다음과 같다. 
* 같은 입력 값은 항상 동일한 해시 체인(=버킷)에 연결됨
* 다른 입력 값이 동일한 해시 체인에 연결될 수 있음
* 해시 체인 내에서 정렬이 보장되지 않음

### 메모리 공유자원에 대한 액세스 직렬화
버퍼캐시는 SGA 구성요소 이므로 버퍼캐시에 캐싱된 버퍼블록은 모두 공유자원이다. 공유자원은 말 그대로 모두에게 권한이 있기 때문에 누구나 접근할 수 있다. 문제는 하나의 버퍼블록을 두 개 이상 프로세스가 동시에 접근하려고 할때 발생한다. 동시에 접근하면 블록 정합성에 문제가 생길 수 있기 때문이다. 따라서 자원을 공유하는 것처럼 보여도 내부에선 한 프로세스씩 순차적으로 접근하도록 구현해야하며, 이를 위해 직렬화 매커니즘이 필요하다. 쉽게 표현하여 줄세우기다. 

같이 사용하는 것처럼 보이지만 특정 순간에는 한 프로세스만 사용할 수 있다. 그 순간 다른 프로세스는 기다려야한다. 이런 직렬화가 가능하게 지원하는 매커니즘이 래치(Latch)다.

SGA를 구성하는 서브 캐시마다 별도의 래치가 존재하는데 버퍼 캐시에는 캐시 버퍼 체인 래치, 캐시버퍼 LRU 체인 래치 등이 작동한다. 빠른 데이터베이스를 구현하려면 버퍼 캐시 히트율을 높여야 하지만, 캐시 I/O도 생각만큼 빠르지 않을 수 있다. 이들 래치에 의한 경합이 생길 수 있기 때문이다. 

캐시버퍼 체인 뿐만 아니라 버퍼블록 자체에도 직렬화 매커니즘이 존재한다. 바로 버퍼 Lock이다. __이러한 직렬화 매커니즘에 의한 캐시 경합을 줄이려면 SQL 튜닝을 통해 쿼리 일량(논리적 I/O)를 줄여야 한다.__ 
  
   


##### 캐시버퍼 체인 래치
대량의 데이터를 읽을 때 모든 블록에 대해 해시 체인을 탐색한다. DBA를 해시 함수에 입력하고 거기서 반환된 값으로 스캔해야 할 해시 체인을 갖는다. 해시 체인을 스캔하는 동안 다른 프로세스가 체인 구조를 변경하는 일이 생기면 곤란하다. 이를 막기 위해 해시 체인 래치가 존재한다. 

  
   
##### 버퍼 Lock
읽고자 하는 블록을 찾았다면 캐시버퍼 체인 래치를 곧바로 해제해야 한다. 그래야 해당 래치가 풀리기를 기다리던 다른 프로세스들이 작업을 재개할 수 있기 때문이다. 
그런데 래치를 해제한 상태로 버퍼블록에 데이터를 읽고 쓰는 도중에 후행 프로세스가 하필 같은 블록에 접근해서 데이터를 읽고 쓴다면 데이터 정합성에 문제가 생길 수 있다. 이를 방지하기 위해 오라클은 버퍼 Lock을 사용한다. 캐시버퍼 체인 래치를 해제하기 전에 버퍼 헤더에 Lock을 설정함으로써 버퍼 블록 자체에 대한 직렬화 문제를 해결하는 것이다. 같은 로우는 로우 Lock에 의해 보호될 텐데 왜 버퍼 Lock이 필요한가 싶지만 로우 Lock을 설정하는 행위도 블록을 변경하는 작업이다. 로우 Lock을 설정하는 순간 다른 프로세스가 해당 블록을 읽는다면 문제 생긴다. 그 뿐만 아니라 같은 블록에서 서로 다른 로우를 동시에 읽고 쓰는 경우를 막기 위해서도 버퍼 Lock은 필요하다. 









